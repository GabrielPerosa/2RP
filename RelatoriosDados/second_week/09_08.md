# Relatório de Estudos

**Nome do Estagiário:** Gabriel Perosa  
**Data:** 09/08/2024

**Módulos/Etapas Feitas:**  
1. **Big Data**
2. **Modelagem de Dados**
3. **Analítico**
4. **Transacional**
5. **BigQuery**
6. **CI/CD**


## Resumo dos módulos 

<h3>1. Big Data</h3><br>

Big Data é o processo de volumes extremamente grandes de diversos dados estruturados, não estruturados e semiestruturados, que exponencialmente crescem com o tempo. Esses conjuntos de dados são tão grandes e complexos que os sistemas tradicionais de gerenciamento de dados não podem analisá-los, armazená-los ou processá-los.<br>
<h5>As Principais caracteristicas ligadas ao Big Data</h5>
<br>

- Volume: característica mais comum do Big Data, ela descreve a enorme quantidade de dados gerados.
- Variedade: os dados podem ser estruturados, semiestruturados ou não estruturados.
- Velocidade: relacionado a alta velocidade de dados gerados.
- Veracidade: relação de qualidade e confiabilidade dos dados.
<br>
<h5>Como funciona o Big Data</h5>
A estratégia central do Big Data é que, quanto mais dados você tiver sobre qualquer coisa, mais insights para tomar decisões melhores, descobrir novas oportunidades de crescimento e aprimorar os modelos de negócios. Para que o estratégia funcione, a integração dos dados brutos devem ser tratados e transformados em uma maneira mais organizada para os analistas de dados. O gerenciamento e armazenamento tambem são pontos a serem considerados, tendo em vista que esses dados muitas vezes precisam ser disponibilizados em tempo real, dessa maneira cada vez mais as empresas estão recorrendo a soluções em nuvem. A etapa final e uma das mais importantes é a análise, ela garante a entrega dos insights, para que as ações possam ser tomadas, afim de garantir maior acertividade para as empresas.<br>
<h5>Principais benefícios do Big Data</h5>

- Melhorar a tomada de decisão
- Maior Agilidade
- Inovações
- Experiência dos clientes
- Melhoria contínua

Diversas empresas ainda não utilizam o Big Data, tendo em vista que os processos teriam que ser retrabalhados, e acabam ficando no "comodismo", porem segundo um artigo (https://cloud.google.com/learn/what-is-big-data?hl=pt-BR) mais de 50% das empresas que utilizão Big Data atingem as metas de receitas.<br>

<h3>2. Modelagem de Dados</h3><br>
A modelagem de dados é o processo que define os sistemas de coleta e gerenciamento de dados em uma empresa, garantindo bancos de dados organizados e eficientes.<br>
<h5>Exemplos de Modelos de Dados</h5>

- Modelo conceitual: oferecem uma visão geral dos dados, explicando regras de negócios, requisitos de segurança, e como são organizados.
- Modelo Lógico: fornecem mais detalhes sobre os conceitos de dados, atributos e as relações de entidades.
- Modelo Físico: mapeia o modelo lógico para a criação de bancos de dados, contendo detalhes de tabelas, índices e outros aspectos técnicos de armazenamento.

<h5>Processo de Modelagem de Dados</h5>
A modelagem de dados inclui diversos processos dependendo de tipo de modelo utilizado, alguns dos principais processos estão:<br>
<br>

- Identificar as entidades e suas propriedades
- Identificar as suas relações 
- Regras de negócios
- Validação
- Otimização

Desa forma os Bancos de Dados ficam mais agéis, evitando redundâncias, melhorando a eficiência e facilidade de manutenção.
<br>

<h3>3. Analítico</h3><br>

As bases analíticas formam sistemas que facilitam a análise de grandes volumes de dados, normalmente usados em conjunto com data warehouse e data lakes, tendo em vista que precisam suportar diversas necessidades de análise de dados. Os sistemas devem ser otimizados para consultas complexas e operações analíticas, dessa forma garantindo maiores insights. 
<br>
<h5>Data Warehouse</h5>
Um Data Warehouse é composto por bases de dados mais estruturadas, armazenando dados ja processados, dessa forma economizando espaço de armazenamento e garantindo bases de dados mais otimizadas.
<br>
<h5>Data Lakes</h5>
Um Data Lakes é composto tanto de dados estruturados como não estruturados, sem a necessidade de processa-los, alem disso pode armazenar diversos tipos de dados, como imagens, textos, dados em tempo real, entre outros. Um Data Lakes pode armazenar diversos tipos de dados variados, oque acaba ficando menos otimizado.
<br>
<br>
Em termos gerais ambos são projetados para armazenar dados, podendo parecer bem idênticos, porem a maior diferença esta no tratamento desses dados. Data Warehouses são usados para armazenar dados estruturados e padronizados. Data Lakes permitem o armazenamento de qualquer tipo de dado, independente de sua estrura ou formato. Isso os torna mais flexíveis e escaláveis, mas também pode tornar a análise de dados mais complexa.


<h5>Principais benefícios do uso de bases analíticas</h5>

- Otimização de consultas
- Capacidade para grandes volumes de dados
- Facilidade na integração de dados
- Uso de modelagem de dados
- Diversas ferramentas para análise de dados
- Insights que ajudam na tomada de decisão

Existem diversas tecnologias usadas atualmente como Apache Spark, Microsoft Azure Synapse Analytics, Google BigQuery, cada uma com suas peculiaridades mas em geral as bases analíticas são cruciais para que as empresas possam garantir maior aproveitamento dos dados, em suas tomadas de decisões.<br>

<h3>4. Transacional</h3><br>
 Bancos de dados transacionais são Projetados para o gerenciamento de banco de dados, tambem voltado para executar sistemas de produção. A grande vantagem desses bancos esta na velocidade, os dados de linhas são salvos muito rapidamente, mantendo a integridade dos dados.
<br>
<h5>Principais benefícios do uso de bases Transacional</h5>

- Integridade dos dados
- Baixa latência
- Velocidade nas operações
- Gerenciamento de Diversos usuarios
- Flexibilidade
- Escalabilidade

<h5>Transação ACID</h5>
O ACID é um conjunto de propriedades que garantem a preservação e integridade dos dados nas transações
<br>
Veja abaixo as definições de cada propriedade:<br>
<br>

- Atomicidade: garante que a transação seja concluida apenas quando finalizar todas as transações, se uma parte falhar, ela não sera concluida.
- Consistência: garante que uma transação sera levada para um bando de dados, caso contrario sera revertida.
- Isolamento: apenas transações concluidas podem ser alteradas.
- Durabilidade: depois de uma transação ter sido confimada, as mudanças continuam em caso de eventuais falhas de sistema.<br>
<br>
Dentre as Principais bases transacionais estão: MySQL, PostgreSQL, Oracle Database e Microsoft SQL Server. São essenciais para empresas que necessitam de processamentos ágeis, com confiabilidade dos dados, garantindo maior segurança entre as transações.<br>

<h3>5. BigQuery</h3><br>
O BigQuery é um data warehouse fornecido pelo Google Cloud, totalmente gerenciado, proporcionando análisar grandes volumes de dados com diversas ferramentas integradas. 

<h5>Principais Vantagens </h5>

- Permite usar SQL sem a necessidade de gerenciar a infraestrutura.

- Arquitetura flexível.

- Valores mais atrativos para empresas, a estrutura de preços é baseada na demanda de computação.

- Otimização do armazenamento de dados com IA.

- Análise de dados em tempo real.

- Armazenamento de grandes volumes de dados.<br>

<br>
O BigQuery permite a análise de dados em tempo real, garantindo relatórios atualizados de forma muito mais rápida.<br>

<br>
Com o BigQuery as empresas eliminam grande parte do trabalho manual, resultando em uma minimização no número de erros, garantindo mais acertividade nas estratégias e tomada de decisão.<br>
<br>

<h3>6. CI/CD</h3><br>
CI/CD uma sigla em inglês para Integração Contínua/Entrega Contínua, cuja abordagem é a otimização para projetos de desenvolvimento de software. Dessa forma se tornando essencial para a área de desenvolvimento de software, pois auxilia na qualidade do código, eficiência do processo de desenvolvimento e a capacidade de implementação do software.<br>

<h5>Integração continua (CI)</h5>

Usada para integrar o código produzido por diversos desenvolvedores em um repositório, de modo que cada integração é verificada por testes automatizados, o objetivo é detectar os erros, para não atrapalhar o desenvolvimento do software.<br>

<h5>Entrega continua (CD)</h5>

A Entrega Contínua faz a parte de automatizar o desenvolvimento, com teste e implantação de uma solução para um ambiente de produção, dessa forma o código sempre fica pronto para implantação em produção, tornando a implantação um processo ágil.<br>

<h5>Principais Vantagens </h5>

- Verificação constante de erros.
- A execução de testes automatizados garantem uma qualidade melhor no software.
- Automatização de tarefas.
- Implantações em produção podem ser feitas com mais frequência e mais facilidade.
- Colaboração entre os desenvolvedores.
- Facilidade para rastrear alterações.
<br>

O uso das práticas de CI/CD são de extrema importância para a automatização do desenvolvimento de software, garantindo mais agilidade em diversas atapas, minimizando erros que podem atrasar o desenvolvimento, alem de permitir um desenvolvimento eficiente em equipe.


<br>


**Desafios Encontrados:**  
Não encontrei desafios.

**Feedback e Ajustes:**  
Na trilha de aprendizado poderia conter exemplos mais práticos.<br>

No Módulo analítico poderia especificar a diferença entre Data Warehouse e Data Lakes.

**Próximos Passos:**  
Continuarei seguindo a Trilha de aprendizado.