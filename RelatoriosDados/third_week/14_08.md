# Relatório de Estudos

**Nome do Estagiário:** Gabriel Perosa  
**Data:** 14/08/2024

**Módulos/Etapas Feitas:**  
1. **Python**
2. **Apache Spark**
3. **PySpark**
4. **Apache Beam**
5. **Google Dataflow**
6. **Apache Airflow**
7. **Mensageria**
8. **Máquinas Virtuais**
9. **Docker**
10. **Kubernetes**
11. **Análise de dados**


## Resumo dos módulos 

<h2>Linguagens e Frameworks</h2>

<h3>1. Python</h3>

A linguagem Python foi criada para facilitar o desenvolvimento, sendo conhecida pela simplicidade e facilidade de escrita, com linhas de códigos mais limpas e legíveis.

<h5>Os Principais benefícios do uso de Python </h5>

- Sintaxe simples
- Fácil interpretação
- Variedades de bibliotecas e frameworks

<h5>Principais bibliotecas</h5>

- Pandas: Biblioteca utilizada para manipulação de 
dados.

- NumPy: Biblioteca para tratamento de dados, oferece suporte para arrays multidimencionas.

- Django: Conjunto de bibliotecas para facilitar o desenvolvimento web.

- TensorFlow: Biblioteca voltada para criação de modelos de inteligência artificial.


Python é uma linguagem de alto nível, simplificada para facilitar o desenvolvimento de diversas aplicações como ciência de dados, aprendizado de máquina, desenvolvimento web, desenvolvimento de software. Uma linguagem muito versátil para diversas aplicações, se tornando muito popular, principalmente para quem esta ingressando na área de programação.<br>

<h3>2. Apache Spark</h3>
O Apache Spark é um framework com mecanismos que facilitam o processamento de dados, muito usado para grandes conjuntos de dados, tendo em vista que foi projetado para oferecer alta velocidade e escalabilidade.

<h3>3. PySpark</h3>
PySpark é uma ferramenta de processamento de dados, que foi desenvolvida com base na linguagem Python e no framework Spark, usada para agilizar a criação de softwares que envolvem grandes volumes de processamento de dados.

<h5>Os Principais benefícios do uso de PySpark </h5>

- Capacidade de processar dados em alta velocidade
- Suporte a varias linguagens
- Diversos usos de aplicações
- Facilidade no desenvolvimento

PySpark oferece uma vasta possibilidade para profissionais que trabalham com dados, tendo em vista a facilidade e velocidade para grandes volumes de dados. <br>

<h3>4. Apache Beam</h3>
Apache Beam é um modelo unificado, de código aberto para a criação de pipelines que podem ser usadas em diferentes sistemas, e possibilita usar diversas linguagens. O Apache Beam é essencial para análise e processamentos em tempo real. <br>

<h3>5. Google Dataflow</h3>
O Google Dataflow é um serviço de processamento de dados em tempo real e em lote, oferecido pelo Google Cloud Platform. Esse serviço facilita o processamento de grandes volumes de dados. O Dataflow utiliza o modelo de programação Apache Beam para processamento de dados.<br>

<h3>6. Apache Airflow</h3>
O Apache Airflow é uma ferramenta de orquestração de fluxo de trabalho de código aberto (open-source), a característica principal do Airflow é a sua capacidade de definir fluxos de trabalhos, e auxiliar no gerenciamento das tarefas.<br>

<h5>Os Principais benefícios do Apache Airflow</h5>

- Escalabilidade
- Flexibilidade
- Monitoramento em tempo real
- Integração com outras ferramentas
<br>

<h3>7. Mensageria</h3>
Mensageria é um conceito aonde permite a comunicação entre sistema distribuidos, por meio de mensagens, proporcionando interação entre sistemas.

<h4>Pub/Sub</h4>
O Pub/Sub é um tipo de mensageria onde permite o disparo de mensagens direcionadas, aonde as mesmas mensagen serão enviadas para uma seleção determinada.

<h4>Fila de mensagens</h4>
Como o nome diz, forma uma fila de mensagens, dessa forma seguindo uma ordem, tambem facilita para que todos tenham acesso as mensagens, e seu processamento sera mais dividido pelos usuarios.

<h4>Mensagem de Ponto a Ponto</h4>
Envolve a troca de mensagens por apenas 2 partes, dessa forma tornando a mensagem direcionada.
<br>

<h3>8. Máquinas Virtuais</h3>
É um ambiente virtual que simula um computador, com todas as suas definições, armazenamento, aplicativos e sistema operacional. As VMs (máquinas virtuais) são executadas em softwares, que ficam em um computador físico, podendo replicar diversas VMs dentro de um unico computador.<br>

<h5>As Principais vantagens</h5>

- Otimização de recursos
- Segurança
- Custos reduzidos
- Portabilidade

<h3>9. Docker</h3>
Docker é uma plataforma de código aberto que suporta linguagens como JavaScript, Python e PHP, e permite que desenvolvedores criem, enviem e executem aplicativos distribuídos. Isso vale para vários formatos, como máquinas virtuais e nuvem. <br>
O Docker permite que aplicativos e dependências sejam alocados juntos em um contêiner, e cada contêiner é executado de maneira independente, dessa forma o gerenciamento de recursos fica mais eficiente.
<br>

<h3>10. Kubernetes</h3>
O Kubernetes é uma plataforma criada para automatização de gerenciamento de contêineres. O Kubernetes tambem permite o dimencionamento das aplicações, oque facilita no balanceamento de recursos. Alem da grande flexibilidade, tendo em vista que seu ambiente suporta diversos tipos de aplicações.
<br>

<h3>11. Análise de dados</h3>
Análise de dados são varios processos que transformam e acompanham as informações, com o intuito de extrair dados, alguns dos processos mais importantes estão a coleta de dados, a limpeza dos dados, preparação, modelagem e visualização. O objetivo principal é extrair insigths para melhorar a tomada de decisões, garantindo maior acertividade e eficiência nos processos.<br>
<br>

**Desafios Encontrados:**  
Não encontrei desafios.

**Feedback e Ajustes:**  
Gostaria de mais exemplos práticos.

**Próximos Passos:**  
Aplicar meus conhecimentos teóricos na prática.
